# -*- coding: utf-8 -*-
#
# WikiXRay: A tool for quantitative analysis of Wikipedia                       
#
# <http://projects.libresoft.es/projects/show/wikixray/>
# <http://gitorious.org/wikixray>
#
# Copyright (c) 2006-2010 Felipe Ortega     
#
# This program is free software: you can redistribute it and/or modify it 
# under the terms of the GNU General Public License as published by 
# the Free Software Foundation, either version 3 of the License, or 
# (at your option) any later version. This program is distributed in the 
# hope that it will be useful, but WITHOUT ANY WARRANTY; without 
# even the implied warranty of MERCHANTABILITY or FITNESS FOR 
# A PARTICULAR PURPOSE. See the GNU General Public License 
# for more details. You should have received a copy of the GNU General Public 
# License along with this program. If not, see <http://www.gnu.org/licenses/>
#
# Author: Felipe Ortega
#
import sys,os,codecs,string, datetime, random, re, time
import dbaccess
from xml.sax import saxutils,make_parser
from xml.sax.handler import feature_namespaces, ContentHandler
from xml.sax.saxutils import XMLFilterBase, XMLGenerator
from optparse import OptionParser

class text_normalize_filter(XMLFilterBase):
    """
    SAX filter to ensure that contiguous texts nodes are merged into one
    That hopefully speeds up the parsing process a lot, specially when reading
    revisions with long text
    Receip by Uche Ogbuji, James Kew and Peter Cogolo
    Retrieved from "Python Cookbook, 2nd ed., by Alex Martelli, Anna Martelli
    Ravenscroft, and David Ascher (O'Reillly Media, 2005) 0-596-00797-3"
    """

    def __init__(self, upstream, downstream):
        XMLFilterBase.__init__(self, upstream)
        self._downstream=downstream
        self._accumulator=[]
    def _complete_text_node(self):
        if self._accumulator:
            self._downstream.characters(''.join(self._accumulator))
            self._accumulator=[]
    def characters(self, text):
        self._accumulator.append(text)
    def ignorableWhiteSpace(self, ws):
        self._accumulator.append(text)

def _wrap_complete(method_name):
    def method(self, *a, **k):
        self._complete_text_node()
        getattr(self._downstream, method_name)(*a, **k)
    method.__name__= method_name
    setattr(text_normalize_filter, method_name, method)
for n in '''startElement endElement endDocument'''.split():
    _wrap_complete(n)

class wikiHandler(ContentHandler):
    """Parse an XML file generated by Wikipedia Export page into SQL data
    suitable to be imported by MySQL"""
    def __init__(self, options):
        self.options=options
        if self.options.monitor and (not self.options.fileout and not self.options.streamout):
            self.acceso = dbaccess.get_Connection(self.options.machine, self.options.port,\
            self.options.user, self.options.passwd, self.options.database)
        self.log_dict = {}
        self.stack=[]
        self.current_text = ''
        self.current_elem=None
        #self.log_count=0
        self.log_num=0

        self.nspace_dict={}
        self.codens=''
        
        ########################################
        ##REGEXPS
        ########################################
        

        ########################################
        #REMAINING GLOBAL ATTRIBUTES
        ########################################
        self.fileErrPath="./errors"+self.options.database+".log"
        self.loginsert=''
        self.loginsertrows=0
        self.loginsertsize=0
        self.start=datetime.datetime.now()
        self.timeCheck=None
        self.timeDelta=None

    def startElement(self, name, attrs):
        ## Here we define which tags we want to catch
        ## Use a stack to diff between log ID and contributor ID
        if name=='logitem' or name=='contributor':
            self.stack.append(name)
        elif name=='namespace':
            self.codens=attrs.get('key')
        elif name=='params':
            self.log_dict[name]=''
        #Clear previous tag name and tag content
        self.current_text=''
        self.current_elem=name
        return
        
    def endElement(self, name):
        
        ## Defining tasks to manage contents from the last readed tag
        ## Catching the namespace of this page
        if name=='namespace':
            self.nspace_dict[self.current_text]=self.codens
    
        elif name=='id':
            if self.stack[-1]=='contributor':
                ##Detecting contributor's attributes inside a revision
                self.log_dict['rev_user']=self.current_text
            elif self.stack[-1]=='logitem':
                self.log_dict[name]=self.current_text
            else:
                self.f=open(self.fileErrPath,'a')
                if len(self.stack)>0:
                    self.f.write("Unsupported parent tag for '"+name+"': "+self.stack[-1])
                    self.stack.pop()
                self.f.close()
            
        elif name=='timestamp':
            ##Adequate formatting of timestamps
            self.log_dict['timestamp']=self.current_text.replace('Z','').replace('T',' ')
                
        elif name=='contributor':
            ##Pop contributor tag from the stack
            self.stack.pop()

        elif name=='logtitle':
            self.log_dict['logtitle']=self.current_text
            ##Recovering namespace for this logitem
            if self.nspace_dict.has_key(self.log_dict['logtitle'].split(':')[0]):
                self.log_dict['namespace']=self.nspace_dict[self.log_dict['logtitle'].split(':')[0]]
            else:
                self.log_dict['namespace']='0'
        
        elif name=='params':
            if self.log_dict['type']=='review' and (self.log_dict['action']=='approve' or self.log_dict['action']=='approve-a' or
            self.log_dict['action']=='unapprove' or self.log_dict['action']=='approve-ia' or self.log_dict['action']=='approve-i'):
                self.log_dict['new_flag']=self.current_text.split('\n')[0]
                try:
                  self.log_dict['old_flag']=self.current_text.split('\n')[1]
                except (IndexError), e:
                  self.printfile = codecs.open("error_"+self.options.database,'a','utf_8')
                  self.printfile.write("Offending logitem was = " + str(self.log_dict['id'])+"\n")
                  self.printfile.write("Offending current_text was = "+ self.current_text+"\n")
                  self.printfile.close()
        #####################################################
        ## END OF LOGITEM
        #####################################################
        elif name=='logitem':
            #self.log_count+=1
                
            ####CONSTRUCTION OF EXTENDED INSERTS FOR LOGITEMS
            ##Values order: (log_id, log_type, log_action, log_timestamp, log_user, log_user_name, log_namespace,
            ##log_title, log_comment, log_params, [new_flag], [old_flag])

            # Build current row for loginsert
            try:
              newloginsert="("+self.log_dict['id']+","+'"'+self.log_dict['type']+'"'+","+\
              '"'+self.log_dict['action']+'"'+","+'"'+self.log_dict['timestamp']+'",'

              if self.log_dict.has_key('rev_user'):
                newloginsert+= self.log_dict['rev_user']
              else:
                newloginsert+= '-1'
              
              newloginsert+=","+'"'
              if self.log_dict.has_key('username'):
                newloginsert+=self.log_dict['username'].replace("\\","\\\\").replace("'","\\'").replace('"', '\\"')
              else:
                newloginsert+='VOID' #Be careful with somebody name VOID, always check whether rev_user==-1 or not in queries

              newloginsert+= '"'+","
              if self.log_dict.has_key('namespace'):
                newloginsert+=self.log_dict['namespace']
              else:
                newloginsert+='-1000'
              
              newloginsert+= ","+'"'+self.log_dict['logtitle'].replace("\\","\\\\").replace("'","\\'").replace('"', '\\"')
              if self.log_dict.has_key('comment'):
                newloginsert+='"'+","+'"'+self.log_dict['comment'].replace("\\","\\\\").replace("'","\\'").replace('"', '\\"')
              else:
                newloginsert+='","'
              
              newloginsert+='"'+","+'"'+self.log_dict['params']+'",'
              #if self.log_dict.has_key('new_flag') and self.log_dict.has_key('old_flag'):
                #newloginsert+=self.log_dict['new_flag']+','+self.log_dict['old_flag']
              if self.log_dict.has_key('new_flag'):
                newloginsert+=self.log_dict['new_flag']+','
              else:
                newloginsert+='0,'
              if self.log_dict.has_key('old_flag'):
                newloginsert+=self.log_dict['old_flag']
              else:
                newloginsert+='0'
              newloginsert+=')'

            # In case that some of the fields is missing or flawed, skip this revision and log to standard error
            except (KeyError), e:
              self.printfile = codecs.open("error_"+self.options.database,'a','utf_8')
              self.printfile.write("Offending log_dict was = \n")
              self.printfile.write(str(self.log_dict))
              self.printfile.write("\n")
              self.printfile.write("====================================================\n")
              self.printfile.write(str(e)+"\n")
              self.printfile.write("====================================================\n\n")
              self.printfile.close()
              return
            
            self.debug(newloginsert)
	    
            ##############################################
            ## LOOK-AHEAD ALGORITHM
            ##############################################
            if self.loginsertrows==0:
                #Always allow at least one row in extended inserts
                self.loginsert="INSERT INTO logging VALUES"+newloginsert
                self.loginsertrows+=1
                #Conservative approach: assuming 2 bytes per UTF-8 character
                self.loginsertsize=len(self.loginsert)*2
            elif (self.loginsertsize+(2*len(newloginsert))<=self.options.imaxsize*1024) and\
            ((self.loginsertrows+1)<=self.options.imaxrows):
                #Append new row to self.loginsert
                self.loginsert+=","+newloginsert
                self.loginsertrows+=1
                #Conservative approach: assuming 2 bytes per UTF-8 character
                self.loginsertsize=len(self.loginsert)*2
            else:
                #We must finish and write currrent insert and begin a new one
                if self.options.fileout:
                    self.loginsert+=";\n"
                    # Write output to SQL file
                    self.revfile = codecs.open(self.options.sqlfile,'a','utf_8')
                    self.revfile.write(self.loginsert)
                    self.revfile.close()
                elif self.options.streamout:
                    # DON'T WRITE SQL TO FILES, GENERATE ENCONDED SQL STREAM FOR MYSQL
                    self.loginsert+=";"
                    print self.loginsert.encode('utf_8')
                elif self.options.monitor:
                    chances=0
                    while chances<5:
                        try:
                            dbaccess.raw_query_SQL(self.acceso[1], self.loginsert.encode('utf_8'))
                        except (Exception), e:
                            self.printfile = codecs.open("error_"+self.options.database,'a','utf_8')
                            self.printfile.write(str(e)+"\n")
                            self.printfile.write(self.loginsert[0:30]+"\n**********************************")
                            self.printfile.close()
                            chances+=1
                        else:
                            break
                self.loginsert="INSERT INTO logging VALUES"+newloginsert
                self.loginsertrows=1
                #Conservative approach: assuming 2 bytes per UTF-8 character
                self.loginsertsize=len(self.loginsert)*2

            ##################################################

            self.log_dict.clear()
            self.stack.pop()
            self.log_num+=1
            if self.options.verbose and self.options.log is None:
                # Display status report
                if self.log_num % 1000 == 0:
                    self.timeCheck=datetime.datetime.now()
                    self.timeDelta=self.timeCheck-self.start
                    if self.timeDelta.seconds==0:
                        print >> sys.stderr, "logitem %d (%f logitems per sec.)"\
                        % (self.log_num, 1e6*float(self.log_num)/self.timeDelta.microseconds)
                        self.printfile = codecs.open(self.fileErrPath,'a','utf_8')
                        self.printfile.write("logitem "+str(self.log_num)+" ("+\
                        str( 1e6*float(self.log_num)/self.timeDelta.microseconds)+" logitems. per sec.)\n")
                        self.printfile.close()
                    else:
                        print >> sys.stderr, "logitem %d (%f logitems per sec.)"\
                        % (self.log_num, float(self.log_num)/self.timeDelta.seconds)
                        self.printfile = codecs.open(self.fileErrPath,'a','utf_8')
                        self.printfile.write("logitem "+str(self.log_num)+" ("+\
                        str( float(self.log_num)/self.timeDelta.seconds)+" logitems. per sec.)\n")
                        self.printfile.close()
            if self.options.verbose and self.options.log is not None:
                if self.log_num%1000==0:
                    #Allow other processes/threads to catch the CPU
                    #time.sleep(1)
                    self.timeCheck=datetime.datetime.now()
                    self.timeDelta=self.timeCheck-self.start
                    if self.timeDelta.seconds==0:
                        print >> sys.stderr, "logitem %d (%f logitems per sec.)"\
                        % (self.log_num, 1e6*float(self.log_num)/self.timeDelta.microseconds)
                        self.printfile = codecs.open(self.options.log,'a','utf_8')
                        self.printfile.write("logitem "+str(self.log_num)+" ("+\
                        str( 1e6*float(self.log_num)/self.timeDelta.microseconds)+" logitems. per sec.)\n")
                        self.printfile.close()
                    else:
                        print >> sys.stderr, "logitem %d (%f logitems per sec.)"\
                        % (self.log_num, float(self.log_num)/self.timeDelta.seconds)
                        self.printfile = codecs.open(self.options.log,'a','utf_8')
                        self.printfile.write("logitem "+str(self.log_num)+" ("+\
                        str( float(self.log_num)/self.timeDelta.seconds)+" logitems. per sec.)\n")
                        self.printfile.close()
        
        ## GENERAL TAG PROCESSING        
        else:
            self.log_dict[self.current_elem]=self.current_text
                
        self.current_elem=None
        return
             
    def characters(self, ch):
        if self.current_elem != None:
            self.current_text = self.current_text + ch
            
    def endDocument(self):
        ################################################
        #We must write the las loginsert before finishing this page
        if self.options.fileout:
            self.loginsert+=";\n"
        # Write output to SQL file
            self.revfile = codecs.open(self.options.sqlfile,'a','utf_8')
            self.revfile.write(self.loginsert)
            self.revfile.close()
        elif self.options.streamout:
            # DON'T WRITE SQL TO FILES, GENERATE ENCONDED SQL STREAM FOR MYSQL
            self.loginsert+=";"
            print self.loginsert.encode('utf_8')
        elif self.options.monitor:
            chances=0
            while chances<5:
                try:
                    dbaccess.raw_query_SQL(self.acceso[1], self.loginsert.encode('utf_8'))
                except (Exception), e:
                    self.printfile = codecs.open("error_"+self.options.database,'a','utf_8')
                    self.printfile.write(str(e)+"\n")
                    self.printfile.write(self.loginsert[0:30]+"\n**********************************")
                    self.printfile.close()
                    chances+=1
                else:
                    break
        #Reset status vars
        self.loginsertrows=0
        self.loginsertsize=0
        
        #Reset status vars
        self.pageinsertrows=0
        self.pageinsertsize=0

        ###CLOSE DATABASE CONNECTION IF WE ARE USING MONITOR MODE
        if self.options.monitor and (not self.options.fileout and not self.options.streamout):
            dbaccess.close_Connection(self.acceso[0])
        
        ################################################
        
        #Checking out total time consumed and display end message
        self.timeCheck=datetime.datetime.now()
        self.timeDelta=self.timeCheck-self.start
        print >> sys.stderr, "\n"
        print >> sys.stderr, "File successfully parsed..."
        print >> sys.stderr, "logitem %d (%f logitems/sec.)" % (self.log_num,\
        float(self.log_num)/self.timeDelta.seconds)
        if self.options.verbose and self.options.log is not None:
            self.printfile = codecs.open(self.options.log,'a','utf_8')
            self.printfile.write("\nFile successfully parsed... logitem "+str(self.log_num)+" ("+\
            str( float(self.log_num)/self.timeDelta.seconds)+" logitems per sec.)\n")
            self.printfile.close()
            
    def debug(self, str):
        self.sqlfile = codecs.open('debug.sql','a','utf_8')
        self.sqlfile.write(str)
        self.sqlfile.write("\n")
        self.sqlfile.close()
######################################################################
######################################################################
##Main zone
if __name__ == '__main__':
    usage = "usage: %prog [options]"
    parserc = OptionParser(usage)
    parserc.add_option("-t","--stubth", dest="stubth", type="int", metavar="STUBTH", default=256,
    help="Max. size in bytes to consider an article as stub [default: %default]")
    parserc.add_option("--sqlfile", dest="sqlfile", default="logging.sql", metavar="FILE",
    help="Name of the SQL file created for the logging table [default: %default]")
    parserc.add_option("--skipnamespaces", dest="skipns", metavar="NAMESPACES",
    help="List of namespaces whose content will be ignored [comma separated values, without "
    "blanks; e.g. --skipnamespaces=name1,name2,name3]")
    parserc.add_option("-i","--inject", dest="inject", metavar="STRING",
    help="Optional string to inject at the very start of articles' text; string "
    "must be provided within quotes (e.g. --inject='my string') or double quotes")
    parserc.add_option("-f","--fileout", dest="fileout", action="store_true", default=False,
    help="Create SQL files from parsed XML dump")
    parserc.add_option("-s","--streamout", dest="streamout", action="store_true", default=False,
    help="Generate an output SQL stream suitable for a direct import into MySQL database")
    parserc.add_option("-m", "--monitor", dest="monitor", action="store_true", default=True,
    help="Insert SQL code directly into MySQL database [default]")
    parserc.add_option("-u", "--user", dest="user", metavar="MySQL_USER",
    help="Username to connect to MySQL database")
    parserc.add_option("-p", "--passwd", dest="passwd", metavar="MySQL_PASSWORD",
    help="Password for MySQL user to access the database")
    parserc.add_option("-d", "--database", dest="database", metavar="DBNAME",
    help="Name of the MySQL database")
    parserc.add_option("--port", dest="port", metavar="MySQL_SERVER_PORT", default=3306, type="int",
    help="Listening port of MySQL server")
    parserc.add_option("--machine", dest="machine", metavar="SERVER_NAME", default="localhost",
    help="Name of MySQL server")
    parserc.add_option("-v", "--verbose", action="store_true", dest="verbose", default=True,
    help="Display standard status reports about the parsing process [default]")
    parserc.add_option("-q", "--quiet", action="store_false", dest="verbose",
    help="Do not display any status reports")
    parserc.add_option("-l","--log", dest="log", metavar="LOGFILE", default="standard_log.log",
    help="Store status reports in a log file; do not display them")
    parserc.add_option("--insertmaxsize", dest="imaxsize", metavar="MAXSIZE", type="int",
    default=156, help="Max size in KB of the MySQL extended inserts [default: %default] "
    "[max: 256]")
    parserc.add_option("--insertmaxnum", dest="imaxrows", metavar="MAXROWS", type="int",
    default=50000, help="Max number of individual rows allowed in the MySQL extended "
    "inserts [default: %default][max: 250000]")
    
    (options, args) = parserc.parse_args()
    if not options.verbose and options.log!=None:
        parserc.error("Error! Illegal combination: options -q and --log options are mutually exclusive")
    if options.monitor and (not options.fileout and not options.streamout) and (options.user==None or options.passwd==None or options.database==None):
        parserc.error("Error! You must provide user, password and database name to execute monitor mode")
    if options.imaxsize>256 or options.imaxsize<=0:
        parserc.error("Error! Illegal value: optional param --insertmaxsize must be between 1 and 256")
    if options.imaxrows>250000 or options.imaxrows<=0:
        parserc.error("Error! Illegal value: optinal param --insertmaxnum must be between 1 250000")
    # Adapt stdout to Unicode UTF-8
    sys.stdout=codecs.EncodedFile(sys.stdout,'utf_8')
    # Create a parser
    parser = make_parser()

    # Tell the parser we are not interested in XML namespaces
    parser.setFeature(feature_namespaces, 0)

    # Create the downstream_handler using our class
    wh = wikiHandler(options)
    
    #Create de filter based in our parser and content handler
    filter_handler = text_normalize_filter(parser, wh)
    #Parse the XML dump
    filter_handler.parse(sys.stdin)
